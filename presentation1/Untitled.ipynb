{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# Copyright (C)                                                       #\n",
    "# 2016 Shangtong Zhang(zhangshangtong.cpp@gmail.com)                  #\n",
    "# 2016 Kenta Shimada(hyperkentakun@gmail.com)                         #\n",
    "# Permission given to modify the code as long as you keep this        #\n",
    "# declaration at the top                                              #\n",
    "#######################################################################\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import heapq\n",
    "def argmax(elements, unique=True):\n",
    "    maxValue = np.max(elements)\n",
    "    candidates = np.where(np.asarray(elements) == maxValue)[0]\n",
    "    if unique:\n",
    "        return np.random.choice(candidates)\n",
    "    return list(candidates)\n",
    "\n",
    "def pad(array, length, defaultValue=0.0):\n",
    "    if len(array) > length:\n",
    "        return array[0: length]\n",
    "    else:\n",
    "        return array + [defaultValue] * (length - len(array))\n",
    "\n",
    "class PriorityQueue:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pq = []\n",
    "        self.entry_finder = {}\n",
    "        self.REMOVED = '<removed-task>'\n",
    "        self.counter = itertools.count()\n",
    "\n",
    "    def addItem(self, item, priority=0):\n",
    "        if item in self.entry_finder:\n",
    "            self.removeItem(item)\n",
    "        count = next(self.counter)\n",
    "        entry = [priority, count, item]\n",
    "        self.entry_finder[item] = entry\n",
    "        heapq.heappush(self.pq, entry)\n",
    "\n",
    "    def removeItem(self, item):\n",
    "        entry = self.entry_finder.pop(item)\n",
    "        entry[-1] = self.REMOVED\n",
    "\n",
    "    def popTask(self):\n",
    "        while self.pq:\n",
    "            priority, count, item = heapq.heappop(self.pq)\n",
    "            if item is not self.REMOVED:\n",
    "                del self.entry_finder[item]\n",
    "                return item, priority\n",
    "        raise KeyError('pop from an empty priority queue')\n",
    "\n",
    "    def empty(self):\n",
    "        return not self.entry_finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Policy\n",
      "[[ 3.30902999  8.78932551  4.42765281  5.3224012   1.49221235]\n",
      " [ 1.52162172  2.9923515   2.25017358  1.90760531  0.5474363 ]\n",
      " [ 0.05085614  0.73820423  0.67314689  0.35821982 -0.40310755]\n",
      " [-0.97355865 -0.43546179 -0.35484864 -0.58557148 -1.18304148]\n",
      " [-1.8576669  -1.34519762 -1.22923364 -1.42288454 -1.97514545]]\n",
      "Optimal Policy\n",
      "[[ 21.97744338  24.41938153  21.97744338  19.41938153  17.47744338]\n",
      " [ 19.77969904  21.97744338  19.77969904  17.80172914  16.02153504]\n",
      " [ 17.80172914  19.77969904  17.80172914  16.02153504  14.41938153]\n",
      " [ 16.02153504  17.80172914  16.02153504  14.41938153  12.97744338]\n",
      " [ 14.41938153  16.02153504  14.41938153  12.97744338  11.67969904]]\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# Copyright (C) 2016 Shangtong Zhang(zhangshangtong.cpp@gmail.com)    #\n",
    "# Permission given to modify the code as long as you keep this        #\n",
    "# declaration at the top                                              #\n",
    "#######################################################################\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "WORLD_SIZE = 5\n",
    "A_POS = [0, 1]\n",
    "A_PRIME_POS = [4, 1]\n",
    "B_POS = [0, 3]\n",
    "B_PRIME_POS = [2, 3]\n",
    "discount = 0.9\n",
    "\n",
    "world = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
    "\n",
    "# left, up, right, down\n",
    "actions = ['L', 'U', 'R', 'D']\n",
    "\n",
    "actionProb = []\n",
    "for i in range(0, WORLD_SIZE):\n",
    "    actionProb.append([])\n",
    "    for j in range(0, WORLD_SIZE):\n",
    "        actionProb[i].append(dict({'L':0.25, 'U':0.25, 'R':0.25, 'D':0.25}))\n",
    "\n",
    "nextState = []\n",
    "actionReward = []\n",
    "for i in range(0, WORLD_SIZE):\n",
    "    nextState.append([])\n",
    "    actionReward.append([])\n",
    "    for j in range(0, WORLD_SIZE):\n",
    "        next = dict()\n",
    "        reward = dict()\n",
    "        if i == 0:\n",
    "            next['U'] = [i, j]\n",
    "            reward['U'] = -1.0\n",
    "        else:\n",
    "            next['U'] = [i - 1, j]\n",
    "            reward['U'] = 0.0\n",
    "\n",
    "        if i == WORLD_SIZE - 1:\n",
    "            next['D'] = [i, j]\n",
    "            reward['D'] = -1.0\n",
    "        else:\n",
    "            next['D'] = [i + 1, j]\n",
    "            reward['D'] = 0.0\n",
    "\n",
    "        if j == 0:\n",
    "            next['L'] = [i, j]\n",
    "            reward['L'] = -1.0\n",
    "        else:\n",
    "            next['L'] = [i, j - 1]\n",
    "            reward['L'] = 0.0\n",
    "\n",
    "        if j == WORLD_SIZE - 1:\n",
    "            next['R'] = [i, j]\n",
    "            reward['R'] = -1.0\n",
    "        else:\n",
    "            next['R'] = [i, j + 1]\n",
    "            reward['R'] = 0.0\n",
    "\n",
    "        if [i, j] == A_POS:\n",
    "            next['L'] = next['R'] = next['D'] = next['U'] = A_PRIME_POS\n",
    "            reward['L'] = reward['R'] = reward['D'] = reward['U'] = 10.0\n",
    "\n",
    "        if [i, j] == B_POS:\n",
    "            next['L'] = next['R'] = next['D'] = next['U'] = B_PRIME_POS\n",
    "            reward['L'] = reward['R'] = reward['D'] = reward['U'] = 5.0\n",
    "\n",
    "        nextState[i].append(next)\n",
    "        actionReward[i].append(reward)\n",
    "\n",
    "# for figure 3.5\n",
    "while True:\n",
    "    # keep iteration until convergence\n",
    "    newWorld = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
    "    for i in range(0, WORLD_SIZE):\n",
    "        for j in range(0, WORLD_SIZE):\n",
    "            for action in actions:\n",
    "                newPosition = nextState[i][j][action]\n",
    "                # bellman equation\n",
    "                newWorld[i, j] += actionProb[i][j][action] * (actionReward[i][j][action] + discount * world[newPosition[0], newPosition[1]])\n",
    "    if np.sum(np.abs(world - newWorld)) < 1e-4:\n",
    "        print('Random Policy')\n",
    "        print(newWorld)\n",
    "        break\n",
    "    world = newWorld\n",
    "\n",
    "# for figure 3.8\n",
    "world = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
    "while True:\n",
    "    # keep iteration until convergence\n",
    "    newWorld = np.zeros((WORLD_SIZE, WORLD_SIZE))\n",
    "    for i in range(0, WORLD_SIZE):\n",
    "        for j in range(0, WORLD_SIZE):\n",
    "            values = []\n",
    "            for action in actions:\n",
    "                newPosition = nextState[i][j][action]\n",
    "                # value iteration\n",
    "                values.append(actionReward[i][j][action] + discount * world[newPosition[0], newPosition[1]])\n",
    "            newWorld[i][j] = np.max(values)\n",
    "    if np.sum(np.abs(world - newWorld)) < 1e-4:\n",
    "        print('Optimal Policy')\n",
    "        print(newWorld)\n",
    "        break\n",
    "    world = newWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.97744338,  24.41938153,  21.97744338,  19.41938153,\n",
       "         17.47744338],\n",
       "       [ 19.77969904,  21.97744338,  19.77969904,  17.8017056 ,\n",
       "         16.02153504],\n",
       "       [ 17.8017056 ,  19.77969904,  17.8017056 ,  16.02153504,\n",
       "         14.41938153],\n",
       "       [ 16.02153504,  17.8017056 ,  16.02153504,  14.41938153,\n",
       "         12.97744338],\n",
       "       [ 14.41938153,  16.02153504,  14.41938153,  12.97744338,\n",
       "         11.67969904]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
